# Head of Data and Integration - Job Description

## Employment Details
- Position Title: Head of Data and Integration
- Reports To: Chief Information Officer (CIO)
- Direct Reports: None initially (individual contributor with strategic leadership)
- Location: Port Melbourne, VIC (Hybrid)
- Employment Type: Permanent, Full-Time

## Purpose of the Role
The Head of Data and Integration is a strategic technical leadership role responsible for establishing and owning JG King's enterprise data architecture. The role will transform how the organization manages, integrates, and leverages data across 9+ core business systems to drive operational excellence and competitive advantage in the residential construction sector.

## Key Responsibilities

### Master Data Management
- Design and implement enterprise master data management (MDM) strategy.
- Establish a single source of truth for critical business entities (jobs, customers, vendors, products).
- Define data ownership, stewardship, and governance frameworks.
- Create and enforce data quality standards and validation rules.
- Manage data lineage and metadata cataloguing.

### Data Lake and Warehousing
- Architect and build enterprise data warehouse or lakehouse solutions.
- Design dimensional models optimized for construction industry analytics.
- Implement gold, silver, and bronze data tier architecture.
- Establish data retention, archival, and lifecycle management policies.
- Ensure Australian data sovereignty and compliance requirements.

### ETL Pipelines and Data Integration
- Design and maintain robust ETL/ELT pipelines across all source systems.
- Build real-time and batch data integration patterns.
- Create standardized data transformation frameworks.
- Implement data quality monitoring and alerting.
- Document data flows and integration architecture.

### Power BI and Analytics
- Own the enterprise Power BI environment (currently 9 workspaces, 500+ DAX measures).
- Develop semantic models and calculation groups.
- Create executive dashboards and operational reports.
- Establish self-service analytics capabilities for business users.
- Manage report performance optimization and refresh schedules.

### System Integrations
- Lead integration projects between core systems: Timberline, Framework, ClickHome, Constructive, OnBase, WMS/BuilderMT, Salesforce.
- Design API integration patterns and middleware solutions.
- Coordinate with vendors on system integration requirements.
- Maintain integration documentation and runbooks.

### Project Implementation
- Lead data workstreams for new system implementations.
- Define data migration strategies for system replacements (for example Builder MT and Redmap).
- Establish data testing and validation frameworks.
- Support AI/ML platform development with quality data pipelines.

## Required Qualifications

### Essential Experience
- 8+ years in data management, data engineering, or business intelligence roles.
- 3+ years in a senior or lead capacity with strategic ownership.
- Proven track record building enterprise data warehouses or lakehouses.
- Deep expertise in ETL/ELT pipeline development and orchestration.
- Advanced Power BI skills including DAX, semantic models, and enterprise deployment.
- Experience with master data management principles and implementation.
- Strong SQL skills across multiple database platforms.

### Technical Skills
- Power BI (Advanced): DAX, Power Query, dataflows, deployment pipelines.
- SQL Server: T-SQL, SSIS, SSAS, stored procedures.
- Data warehousing: Dimensional modeling, slowly changing dimensions, fact tables.
- ETL tools: Azure Data Factory, SSIS, or equivalent.
- Python or similar for data transformation and automation.
- API integration and REST/SOAP web services.
- Cloud platforms: Azure preferred (Data Factory, Synapse, Fabric).

### Desirable
- Construction, property, or project-based industry experience.
- Experience with Sage Timberline, ClickHome, or similar construction software.
- Knowledge of Australian data privacy and sovereignty requirements.
- Microsoft Fabric or modern data platform experience.
- Machine learning pipeline development.
- Relevant certifications (Azure Data Engineer, Power BI, etc.).

### Personal Attributes
- Strategic thinker who can translate business needs into technical solutions.
- Strong stakeholder management and communication skills.
- Self-motivated with ability to work autonomously.
- Detail-oriented with commitment to data quality.
- Comfortable operating in a mid-sized company environment.
- Collaborative approach with IT team and business users.
